import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import csv
import numpy as np
from difflib import SequenceMatcher
import re
from functools import lru_cache


st.set_page_config(
    page_title="Diagnostic CRM vs BI",
    page_icon="WYZ-Etoile-Bleu 1.png", 
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data(show_spinner=False)
def load_accounts_file(uploaded_file_bytes, file_name):
    """Load uploaded Accounts file handling malformed CSV lines - optimized with caching."""
    if file_name.endswith(".csv"):
        try:
            try:
                content = uploaded_file_bytes.decode('utf-8')
            except UnicodeDecodeError:
                content = uploaded_file_bytes.decode('iso-8859-1')
            
            first_line = content.split('\n')[0]
            delimiter = ',' if ',' in first_line else ';' if ';' in first_line else '\t'
            
            from io import StringIO
            df = pd.read_csv(StringIO(content), sep=delimiter, engine="c", low_memory=False)
        except Exception:
            from io import BytesIO
            df = pd.read_csv(BytesIO(uploaded_file_bytes), engine="python", on_bad_lines="skip")
    else:
        from io import BytesIO
        df = pd.read_excel(BytesIO(uploaded_file_bytes), engine='openpyxl')
    
    return df

def normalize_bool(val):
    """Return True if val looks like a positive boolean."""
    if pd.isna(val):
        return False
    val_str = str(val).strip().lower()
    return val_str in {"true", "1", "yes", "y", "t", "match"}

@lru_cache(maxsize=100)
def get_field_display_name(col):
    """Convert IsEquals column name to display format like name(CRM)/company(BI) - cached."""
    base_field = col.replace("_IsEquals", "").replace("_IsEqual", "")
    
    parts = base_field.split('_')
    if len(parts) >= 2:
        first_field = '_'.join(parts[:-1])
        second_field = parts[-1]
        return f"{first_field}(CRM)/{second_field}(BI)"
    else:
        return f"{base_field}(CRM)/{base_field}(BI)"

@st.cache_data(show_spinner=False)
def compute_comprehensive_analysis(data):
    """Compute comprehensive analysis of data quality - bas√© sur la version fonctionnelle."""
    eq_cols = [c for c in data.columns if "IsEquals" in c or "IsEqual" in c]
    
    if not eq_cols:
        return {}, {}, pd.DataFrame(), pd.DataFrame(), []
    
    total_rows = len(data)
    field_stats = []
    detailed_stats = []
    field_debug_data = []  
    rows_with_nomatch = 0
    if eq_cols:
        has_nomatch_per_row = pd.Series(False, index=data.index)
        
        for col in eq_cols:

            col_values = data[col].astype(str).str.strip().str.lower()
            no_match_series = col_values.isin({"no match", "nomatch", "no_match", "false", "0", "no", "n", "f"})
            has_nomatch_per_row |= no_match_series
        
        rows_with_nomatch = int(has_nomatch_per_row.sum())
    
    rows_iso = total_rows - rows_with_nomatch
    

    for col in eq_cols:

        col_index = data.columns.get_loc(col)
        

        if col_index < 2:
            continue
            
        # R√©cup√©rer les 2 colonnes pr√©c√©dentes
        col_before_1 = data.columns[col_index - 2]  
        col_before_2 = data.columns[col_index - 1] 
        
        # Identifier quelle colonne est CRM et laquelle est BI
        if "_CRM" in col_before_1 and "_BI" in col_before_2:
            crm_col = col_before_1
            bi_col = col_before_2
        elif "_BI" in col_before_1 and "_CRM" in col_before_2:
            crm_col = col_before_2
            bi_col = col_before_1
        else:

            continue
        

        match_series = data[col].apply(normalize_bool)
        match_count = int(match_series.sum())
        
        both_null_series = data[col].astype(str).str.strip().str.lower().isin(['both null', 'bothnull', 'null', 'both_null'])
        both_null_count = int(both_null_series.sum())
        
        no_match_count = total_rows - match_count - both_null_count
        
        # Analyse d√©taill√©e des cas No Match avec la nouvelle logique
        crm_null_bi_value = 0
        bi_null_crm_value = 0
        different_values = 0
        
        debug_info = {
            'col': col,
            'col_index': col_index,
            'crm_col': crm_col,
            'bi_col': bi_col,
            'no_match_count': no_match_count,
            'sample_data': None,
            'results': {}
        }
        
        if no_match_count > 0:

            no_match_mask = ~match_series & ~both_null_series
            no_match_data = data[no_match_mask]
            
            debug_info['filtered_count'] = len(no_match_data)
            
            if len(no_match_data) > 0:

                sample_cols = [crm_col, bi_col, col]
                debug_info['sample_data'] = no_match_data[sample_cols].head(10)
                

                for idx, row in no_match_data.iterrows():
                    crm_val = row[crm_col]
                    bi_val = row[bi_col]
                    

                    if (pd.isna(crm_val) or str(crm_val).strip() == '') and (pd.notna(bi_val) and str(bi_val).strip() != ''):
                        crm_null_bi_value += 1

                    elif (pd.isna(bi_val) or str(bi_val).strip() == '') and (pd.notna(crm_val) and str(crm_val).strip() != ''):
                        bi_null_crm_value += 1

                    elif (pd.notna(crm_val) and str(crm_val).strip() != '') and (pd.notna(bi_val) and str(bi_val).strip() != ''):
                        different_values += 1
                    else:
                        different_values += 1
                
                debug_info['results'] = {
                    'crm_null_bi_value': crm_null_bi_value,
                    'bi_null_crm_value': bi_null_crm_value,
                    'different_values': different_values
                }
        
        field_debug_data.append(debug_info)
        
        match_rate = (match_count / total_rows * 100) if total_rows > 0 else 0
        display_name = get_field_display_name(col)
        
        field_stats.append({
            'field': display_name,
            'match': match_count,
            'no_match': no_match_count,
            'both_null': both_null_count,
            'match_rate': round(match_rate, 2)
        })
        
        detailed_stats.append({
            'field': display_name,
            'match': match_count,
            'both_null': both_null_count,
            'crm_null_bi_value': crm_null_bi_value,
            'bi_null_crm_value': bi_null_crm_value,
            'different_values': different_values
        })
    
    field_stats_df = pd.DataFrame(field_stats)
    detailed_stats_df = pd.DataFrame(detailed_stats)
    

    total_match = int(field_stats_df['match'].sum()) if not field_stats_df.empty else 0
    total_both_null = int(field_stats_df['both_null'].sum()) if not field_stats_df.empty else 0
    total_crm_null = int(detailed_stats_df['crm_null_bi_value'].sum()) if not detailed_stats_df.empty else 0
    total_bi_null = int(detailed_stats_df['bi_null_crm_value'].sum()) if not detailed_stats_df.empty else 0
    total_different = int(detailed_stats_df['different_values'].sum()) if not detailed_stats_df.empty else 0
    
    overall_stats = {
        'total_match': total_match,
        'total_both_null': total_both_null,
        'total_crm_null': total_crm_null,
        'total_bi_null': total_bi_null,
        'total_different': total_different,
    }
    
    row_stats = {
        'rows_with_nomatch': rows_with_nomatch,
        'rows_iso': rows_iso
    }
    
    return overall_stats, row_stats, field_stats_df, detailed_stats_df, field_debug_data

def create_quality_metrics_dashboard(field_stats_df, overall_stats):
    """Create quality metrics dashboard with detailed breakdown."""
    st.markdown("## üìä M√©triques de qualit√© globales")
    

    total_match = overall_stats.get('total_match', 0)
    total_both_null = overall_stats.get('total_both_null', 0)
    total_crm_null = overall_stats.get('total_crm_null', 0)
    total_bi_null = overall_stats.get('total_bi_null', 0)
    total_different = overall_stats.get('total_different', 0)
    
    total_comparisons = total_match + total_both_null + total_crm_null + total_bi_null + total_different
    match_rate = (total_match / total_comparisons * 100) if total_comparisons > 0 else 0
    
    # Premi√®re ligne de m√©triques
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üéØ Taux de correspondance global", f"{match_rate:.1f}%")
    with col2:
        st.metric("‚úÖ Total correspondances", f"{total_match:,}")
    with col3:
        st.metric("‚ö™ Valeurs nulles (deux c√¥t√©s)", f"{total_both_null:,}")
    with col4:
        st.metric("üîÑ Valeurs diff√©rentes", f"{total_different:,}")
    
    # Deuxi√®me ligne de m√©triques pour les cas null
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric("üì§ CRM null / BI valeur", f"{total_crm_null:,}")
    with col6:
        st.metric("üì• BI null / CRM valeur", f"{total_bi_null:,}")
    with col7:
        total_no_match = total_crm_null + total_bi_null + total_different
        st.metric("‚ùå Total √©carts", f"{total_no_match:,}")
    with col8:
        st.metric("üìä Total comparaisons", f"{total_comparisons:,}")
    
    # Graphique d√©taill√©
    pie_data = pd.DataFrame([
        {'status': 'Correspondances', 'count': total_match},
        {'status': 'Valeurs nulles (deux c√¥t√©s)', 'count': total_both_null},
        {'status': 'CRM null / BI valeur', 'count': total_crm_null},
        {'status': 'BI null / CRM valeur', 'count': total_bi_null},
        {'status': 'Valeurs diff√©rentes', 'count': total_different}
    ])
    
    colors = ["#7fbfdc", "#4cadb4", "#6ba6b6", "#78b495", "#82b86a"]
    
    fig_pie = px.pie(
        pie_data, 
        names='status', 
        values='count',
        title="ü•ß R√©partition d√©taill√©e de la qualit√© des donn√©es",
        color_discrete_sequence=colors
    )
    fig_pie.update_traces(hole=0.4)
    fig_pie.update_layout(showlegend=True, height=500)
    st.plotly_chart(fig_pie, use_container_width=True)

def create_field_analysis_charts(field_stats_df):
    """Create detailed field analysis charts - optimized."""
    st.markdown("## üìà Analyse d√©taill√©e")
    
    if field_stats_df.empty:
        st.warning("Aucune donn√©e d'analyse de champ disponible")
        return
    
    # Graphique 1 : optimis√©
    df_sorted = field_stats_df.sort_values('match_rate')
    
    fig_match_rate = px.bar(
        df_sorted,
        x='match_rate',
        y='field',
        orientation='h',
        title="üìä Taux de correspondance par champ (%)",
        color='match_rate',
        color_continuous_scale=[[0, "#6ba6b6"], [0.5, "#4cadb4"], [1, "#7fbfdc"]],
        text='match_rate'
    )
    fig_match_rate.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
    fig_match_rate.update_layout(height=max(400, len(field_stats_df) * 25), showlegend=False)
    st.plotly_chart(fig_match_rate, use_container_width=True)
    
    # Graphique 2 : optimis√© avec melt
    status_df = field_stats_df.melt(
        id_vars=['field'], 
        value_vars=['match', 'no_match', 'both_null'],
        var_name='status', 
        value_name='count'
    )
    
    # Mapper les noms
    status_mapping = {
        'match': 'Correspondances',
        'no_match': '√âcarts', 
        'both_null': 'Valeurs nulles'
    }
    status_df['status'] = status_df['status'].map(status_mapping)
    
    color_map = {
        'Correspondances': '#7fbfdc',
        '√âcarts': '#6ba6b6',
        'Valeurs nulles': '#4cadb4'
    }
    
    fig_stacked = px.bar(
        status_df,
        x='field',
        y='count',
        color='status',
        title="üìö R√©partition d√©taill√©e par champ",
        color_discrete_map=color_map
    )
    fig_stacked.update_xaxes(tickangle=45)
    fig_stacked.update_layout(height=500)
    st.plotly_chart(fig_stacked, use_container_width=True)

def create_advanced_analytics(df, field_stats_df, detailed_stats_df):
    """Create advanced analytics with business rules."""
    st.markdown("## üî¨ Analyses avanc√©es")
    
    if field_stats_df.empty or detailed_stats_df.empty:
        st.warning("Pas de donn√©es pour l'analyse avanc√©e")
        return
    
    # Graphique de r√©partition d√©taill√©e par type
    st.markdown("### üìä R√©partition d√©taill√©e par champ et type")
    
    try:
        detailed_data = []
        for _, row in detailed_stats_df.iterrows():
            detailed_data.extend([
                {'field': row['field'], 'type': 'Correspondances', 'count': row['match']},
                {'field': row['field'], 'type': 'Valeurs nulles (deux c√¥t√©s)', 'count': row['both_null']},
                {'field': row['field'], 'type': 'CRM null / BI valeur', 'count': row['crm_null_bi_value']},
                {'field': row['field'], 'type': 'BI null / CRM valeur', 'count': row['bi_null_crm_value']},
                {'field': row['field'], 'type': 'Valeurs diff√©rentes', 'count': row['different_values']}
            ])
        
        detailed_df = pd.DataFrame(detailed_data)
        
        color_map = {
            'Correspondances': '#7fbfdc',
            'Valeurs nulles (deux c√¥t√©s)': '#4cadb4',
            'CRM null / BI valeur': '#6ba6b6',
            'BI null / CRM valeur': '#78b495',
            'Valeurs diff√©rentes': '#82b86a'
        }
        
        fig_detailed = px.bar(
            detailed_df,
            x='field',
            y='count',
            color='type',
            title="üìö R√©partition d√©taill√©e par champ et type de situation",
            color_discrete_map=color_map
        )
        fig_detailed.update_xaxes(tickangle=45)
        fig_detailed.update_layout(height=600)
        st.plotly_chart(fig_detailed, use_container_width=True)
        
    except Exception as e:
        st.error(f"Erreur dans le graphique d√©taill√©: {str(e)}")
    
    # Matrice de priorisation 
    st.markdown("### üéØ Matrice de priorisation")
    
    try:

        df_priority = detailed_stats_df.copy()
        df_priority['total_records'] = (df_priority['match'] + df_priority['both_null'] + 
                                      df_priority['crm_null_bi_value'] + df_priority['bi_null_crm_value'] + 
                                      df_priority['different_values'])
        

        df_priority['total_records'] = df_priority['total_records'].replace(0, 1)
        
        # R√®gle 1: Plus de Both Null = Plus de complexit√©
        df_priority['both_null_rate'] = df_priority['both_null'] / df_priority['total_records']
        
        # R√®gle 2: Plus de valeurs diff√©rentes = Plus d'impact m√©tier  
        df_priority['different_values_rate'] = df_priority['different_values'] / df_priority['total_records']
        

        df_priority['fix_complexity'] = np.where(
            df_priority['both_null_rate'] == 0, 1,  # Pas de Both Null = facile
            np.where(df_priority['both_null_rate'] <= 0.1, 2,  # Peu de Both Null = assez facile
            np.where(df_priority['both_null_rate'] <= 0.3, 3,  # Moyen
            np.where(df_priority['both_null_rate'] <= 0.6, 4, 5)))  # Beaucoup = difficile
        )
        

        df_priority['business_impact'] = df_priority['different_values_rate'] * 5
        
        fig_priority = px.scatter(
            df_priority,
            x='fix_complexity',
            y='business_impact',
            size='different_values',
            hover_data=['field', 'both_null_rate', 'different_values_rate'],
            title="üéØ Matrice de priorisation (Impact m√©tier vs Complexit√© de correction)",
            labels={
                'fix_complexity': 'Complexit√© de correction (1=facile, 5=difficile)',
                'business_impact': 'Impact m√©tier (bas√© sur valeurs diff√©rentes)'
            },
            color='business_impact',
            color_continuous_scale=[[0, "#7fbfdc"], [0.5, "#78b495"], [1, "#82b86a"]]
        )
        

        fig_priority.add_hline(y=2.5, line_dash="dash", line_color="gray", annotation_text="Impact moyen")
        fig_priority.add_vline(x=3, line_dash="dash", line_color="gray", annotation_text="Complexit√© moyenne")
        

        fig_priority.add_annotation(x=1.5, y=4, text="üö® PRIORIT√â MAX<br>(Facile + Impact √©lev√©)", 
                                   bgcolor="rgba(255,0,0,0.1)", bordercolor="red")
        fig_priority.add_annotation(x=4.5, y=4, text="üéØ PLANIFIER<br>(Difficile + Impact √©lev√©)", 
                                   bgcolor="rgba(255,165,0,0.1)", bordercolor="orange")
        fig_priority.add_annotation(x=1.5, y=1, text="‚úÖ QUICK WINS<br>(Facile + Impact faible)", 
                                   bgcolor="rgba(0,255,0,0.1)", bordercolor="green")
        fig_priority.add_annotation(x=4.5, y=1, text="‚è≥ REPORTER<br>(Difficile + Impact faible)", 
                                   bgcolor="rgba(128,128,128,0.1)", bordercolor="gray")
        
        fig_priority.update_layout(height=600)
        st.plotly_chart(fig_priority, use_container_width=True)
        
    except Exception as e:
        st.error(f"Erreur dans la matrice de priorisation: {str(e)}")

def create_field_by_field_analysis(field_debug_data, selected_fields):
    """Create field by field analysis for selected fields."""
    st.markdown("## üîç Analyse champ par champ")
    
    if not selected_fields:
        st.info("S√©lectionnez des champs dans la barre lat√©rale pour voir l'analyse d√©taill√©e.")
        return
    
    for debug_info in field_debug_data:
        if debug_info['col'] in selected_fields:
            st.write(f"### üîç **Analyse de {debug_info['col']}:**")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"**Position:** colonne {debug_info['col_index']}")
            with col2:
                st.write(f"**Colonne CRM:** {debug_info['crm_col']}")
            with col3:
                st.write(f"**Colonne BI:** {debug_info['bi_col']}")
            
            st.write(f"**Lignes No Match:** {debug_info['no_match_count']}")
            
            if debug_info.get('sample_data') is not None and not debug_info['sample_data'].empty:
                st.write("**√âchantillon des donn√©es No Match:**")
                st.dataframe(debug_info['sample_data'], use_container_width=True)
                
                if debug_info['results']:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("CRM null / BI valeur", debug_info['results']['crm_null_bi_value'])
                    with col2:
                        st.metric("BI null / CRM valeur", debug_info['results']['bi_null_crm_value'])
                    with col3:
                        st.metric("Valeurs diff√©rentes", debug_info['results']['different_values'])
            else:
                st.info("Aucune donn√©e No Match pour ce champ")
            
            st.write("---")


st.markdown("""
# Diagnostic CRM vs BI
### Diagnostic complet pour l'am√©lioration de la correspondance des donn√©es
""")

# Sidebar avec bouton Appliquer
with st.sidebar:
    st.markdown("## üìÅ Upload de fichier")
    uploaded_file = st.file_uploader(
        "Choisir un fichier de comparaison",
        type=["xlsx", "csv"],
        help="Fichier Excel ou CSV contenant les comparaisons CRM vs BI"
    )
    
    if uploaded_file:
        st.success(f"‚úÖ Fichier charg√©: {uploaded_file.name}")
        
        st.markdown("## ‚öôÔ∏è Options d'analyse")
        show_quality_metrics = st.checkbox("üìä M√©triques de qualit√© globales", value=True)
        show_field_analysis = st.checkbox("üìà Analyse d√©taill√©e", value=True)
        show_advanced = st.checkbox("üî¨ Analyses avanc√©es", value=True)
        show_field_by_field = st.checkbox("üîç Analyse champ par champ", value=False)
        
        # Selectbox pour les champs √† analyser (seulement si l'option est coch√©e)
        selected_fields = []
        if show_field_by_field:
            st.markdown("### üéØ S√©lection des champs")
            if 'df_loaded' in st.session_state:
                df = st.session_state.df_loaded
                eq_cols = [c for c in df.columns if "IsEquals" in c or "IsEqual" in c]
                selected_fields = st.multiselect(
                    "Choisir les champs √† analyser en d√©tail:",
                    options=eq_cols,
                    default=[],
                    help="S√©lectionnez les colonnes IsEquals que vous voulez analyser"
                )
            else:
                st.info("Veuillez d'abord charger un fichier pour voir les champs disponibles")
        
        st.markdown("---")
        
        # Bouton 
        apply_analysis = st.button(
            " Appliquer l'analyse", 
            type="primary",
            use_container_width=True,
            help="Lancer l'analyse avec les options s√©lectionn√©es"
        )
        

        if 'analysis_applied' not in st.session_state:
            st.session_state.analysis_applied = False
        
        if apply_analysis:
            st.session_state.analysis_applied = True
            st.session_state.show_quality_metrics = show_quality_metrics
            st.session_state.show_field_analysis = show_field_analysis
            st.session_state.show_advanced = show_advanced
            st.session_state.show_field_by_field = show_field_by_field
            st.session_state.selected_fields = selected_fields


if uploaded_file is not None and st.session_state.get('analysis_applied', False):
    try:

        if 'df_loaded' not in st.session_state or st.session_state.get('last_file_name') != uploaded_file.name:
            with st.spinner("üîÑ Chargement du fichier..."):
                file_bytes = uploaded_file.read()
                uploaded_file.seek(0)  
                df = load_accounts_file(file_bytes, uploaded_file.name)
                st.session_state.df_loaded = df
                st.session_state.last_file_name = uploaded_file.name
        else:
            df = st.session_state.df_loaded
        

        with st.spinner("‚ö° Analyse en cours..."):
            overall_stats, row_stats, field_stats_df, detailed_stats_df, field_debug_data = compute_comprehensive_analysis(df)
        
        # M√©triques de base
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total lignes", f"{len(df):,}")
        with col2:
            eq_cols = [c for c in df.columns if "IsEquals" in c]
            st.metric("üîó Champs compar√©s", len(eq_cols))
        with col3:
            st.metric("üö® Lignes avec au moins 1 √©cart", f"{row_stats.get('rows_with_nomatch', 0):,}")
        with col4:
            st.metric("‚úÖ Lignes ISO", f"{row_stats.get('rows_iso', 0):,}")
        
        # Analyses conditionnelles bas√©es sur les options
        if st.session_state.get('show_quality_metrics', True) and overall_stats:
            create_quality_metrics_dashboard(field_stats_df, overall_stats)
        
        if st.session_state.get('show_field_analysis', True) and not field_stats_df.empty:
            create_field_analysis_charts(field_stats_df)
        
        if st.session_state.get('show_advanced', True) and not field_stats_df.empty:
            create_advanced_analytics(df, field_stats_df, detailed_stats_df)
        
        if st.session_state.get('show_field_by_field', False):
            selected_fields = st.session_state.get('selected_fields', [])
            create_field_by_field_analysis(field_debug_data, selected_fields)
        
        # Aper√ßu des donn√©es
        st.markdown("## üëÄ Aper√ßu des donn√©es")
        
        with st.expander("üìä Statistiques r√©sum√©es"):
            st.dataframe(field_stats_df, use_container_width=True)
        
        with st.expander("üîç √âchantillon des donn√©es brutes"):
            st.dataframe(df.head(20), use_container_width=True)
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du traitement du fichier: {str(e)}")
        st.info("üí° V√©rifiez le format de votre fichier et r√©essayez.")
        
        with st.expander("üîç Informations de d√©bogage"):
            st.code(f"Type d'erreur: {type(e).__name__}")
            st.code(f"Message: {str(e)}")

elif uploaded_file is not None and not st.session_state.get('analysis_applied', False):
    st.info("üëÜ Configurez vos options d'analyse dans la barre lat√©rale et cliquez sur **' Appliquer l'analyse'** pour commencer.")

else:
    # Welcome screen
    st.markdown("""
    ## üëã Bienvenue dans l'outil d'analyse de qualit√© des donn√©es
    
    Cet outil vous permet d'analyser la qualit√© de correspondance entre vos donn√©es CRM et BI.
    
    ###  Pour commencer :
    1. **üìÅ Uploadez votre fichier** dans la barre lat√©rale (Excel ou CSV)
    2. **‚öôÔ∏è Configurez les options** d'analyse selon vos besoins
    3. **üöÄ Cliquez sur "Appliquer l'analyse"** pour lancer le traitement
    4. **üìä Explorez les r√©sultats** avec les graphiques interactifs
    
    ### Optimisations de performance :
    - üîÑ **Ce code n'est pas le plus optimis√© possible, il est donc possible que la premi√®re analyse prenne 1 minute pour g√©n√©rer les diff√©rents graphiques**
    """)
    
   