import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import csv
import numpy as np
from difflib import SequenceMatcher
import re
from functools import lru_cache

st.set_page_config(
    page_title="Diagnostic CRM vs BI",
    page_icon="WYZ-Etoile-Bleu 1.png", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Navigation entre les pages
page = st.sidebar.selectbox(
    "ğŸ—‚ï¸ Choisir le mode d'analyse",
    ["ğŸ“„ Analyse Simple", "ğŸ§© Analyse FragmentÃ©e"],
    help="Analyse Simple: 1 fichier (max 200MB)\nAnalyse FragmentÃ©e: Plusieurs fichiers Ã  combiner"
)

@st.cache_data(show_spinner=False)
def load_accounts_file(uploaded_file_bytes, file_name):
    """Load uploaded Accounts file handling malformed CSV lines - optimized with caching."""
    if file_name.endswith(".csv"):
        try:
            try:
                content = uploaded_file_bytes.decode('utf-8')
            except UnicodeDecodeError:
                content = uploaded_file_bytes.decode('iso-8859-1')
            
            first_line = content.split('\n')[0]
            delimiter = ',' if ',' in first_line else ';' if ';' in first_line else '\t'
            
            from io import StringIO
            df = pd.read_csv(StringIO(content), sep=delimiter, engine="c", low_memory=False)
        except Exception:
            from io import BytesIO
            df = pd.read_csv(BytesIO(uploaded_file_bytes), engine="python", on_bad_lines="skip")
    else:
        from io import BytesIO
        df = pd.read_excel(BytesIO(uploaded_file_bytes), engine='openpyxl')
    
    return df

def combine_dataframes(dataframes_list):
    """Combine multiple dataframes intelligently."""
    if not dataframes_list:
        return pd.DataFrame()
    
    if len(dataframes_list) == 1:
        return dataframes_list[0]
    
    # VÃ©rifier que toutes les DataFrames ont les mÃªmes colonnes
    base_columns = set(dataframes_list[0].columns)
    all_same_columns = all(set(df.columns) == base_columns for df in dataframes_list)
    
    if all_same_columns:
        # ConcatÃ©nation simple si mÃªme structure
        combined_df = pd.concat(dataframes_list, ignore_index=True)
        st.success(f"âœ… {len(dataframes_list)} fichiers combinÃ©s avec succÃ¨s ({len(combined_df)} lignes au total)")
    else:
        # ConcatÃ©nation avec union des colonnes si structures diffÃ©rentes
        combined_df = pd.concat(dataframes_list, ignore_index=True, sort=False)
        st.warning(f"âš ï¸ Les fichiers ont des structures diffÃ©rentes. {len(dataframes_list)} fichiers combinÃ©s avec union des colonnes.")
    
    return combined_df

def normalize_bool(val):
    """Return True if val looks like a positive boolean."""
    if pd.isna(val):
        return False
    val_str = str(val).strip().lower()
    return val_str in {"true", "1", "yes", "y", "t", "match"}

@lru_cache(maxsize=100)
def get_field_display_name(col):
    """Convert IsEquals column name to display format like name(CRM)/company(BI) - cached."""
    base_field = col.replace("_IsEquals", "").replace("_IsEqual", "")
    
    parts = base_field.split('_')
    if len(parts) >= 2:
        first_field = '_'.join(parts[:-1])
        second_field = parts[-1]
        return f"{first_field}(CRM)/{second_field}(BI)"
    else:
        return f"{base_field}(CRM)/{base_field}(BI)"

@st.cache_data(show_spinner=False)
def compute_comprehensive_analysis(data):
    """Compute comprehensive analysis of data quality - basÃ© sur la version fonctionnelle."""
    eq_cols = [c for c in data.columns if "IsEquals" in c or "IsEqual" in c]
    
    if not eq_cols:
        return {}, {}, pd.DataFrame(), pd.DataFrame(), []
    
    total_rows = len(data)
    field_stats = []
    detailed_stats = []
    field_debug_data = []  
    rows_with_nomatch = 0
    if eq_cols:
        has_nomatch_per_row = pd.Series(False, index=data.index)
        
        for col in eq_cols:
            col_values = data[col].astype(str).str.strip().str.lower()
            no_match_series = col_values.isin({"no match", "nomatch", "no_match", "false", "0", "no", "n", "f"})
            has_nomatch_per_row |= no_match_series
        
        rows_with_nomatch = int(has_nomatch_per_row.sum())
    
    rows_iso = total_rows - rows_with_nomatch
    
    for col in eq_cols:
        col_index = data.columns.get_loc(col)
        
        if col_index < 2:
            continue
            
        # RÃ©cupÃ©rer les 2 colonnes prÃ©cÃ©dentes
        col_before_1 = data.columns[col_index - 2]  
        col_before_2 = data.columns[col_index - 1] 
        
        # Identifier quelle colonne est CRM et laquelle est BI
        if "_CRM" in col_before_1 and "_BI" in col_before_2:
            crm_col = col_before_1
            bi_col = col_before_2
        elif "_BI" in col_before_1 and "_CRM" in col_before_2:
            crm_col = col_before_2
            bi_col = col_before_1
        else:
            continue
        
        match_series = data[col].apply(normalize_bool)
        match_count = int(match_series.sum())
        
        both_null_series = data[col].astype(str).str.strip().str.lower().isin(['both null', 'bothnull', 'null', 'both_null'])
        both_null_count = int(both_null_series.sum())
        
        no_match_count = total_rows - match_count - both_null_count
        
        # Analyse dÃ©taillÃ©e des cas No Match avec la nouvelle logique
        crm_null_bi_value = 0
        bi_null_crm_value = 0
        different_values = 0
        
        debug_info = {
            'col': col,
            'col_index': col_index,
            'crm_col': crm_col,
            'bi_col': bi_col,
            'no_match_count': no_match_count,
            'sample_data': None,
            'results': {}
        }
        
        if no_match_count > 0:
            no_match_mask = ~match_series & ~both_null_series
            no_match_data = data[no_match_mask]
            
            debug_info['filtered_count'] = len(no_match_data)
            
            if len(no_match_data) > 0:
                sample_cols = [crm_col, bi_col, col]
                debug_info['sample_data'] = no_match_data[sample_cols].head(10)
                
                for idx, row in no_match_data.iterrows():
                    crm_val = row[crm_col]
                    bi_val = row[bi_col]
                    
                    if (pd.isna(crm_val) or str(crm_val).strip() == '') and (pd.notna(bi_val) and str(bi_val).strip() != ''):
                        crm_null_bi_value += 1
                    elif (pd.isna(bi_val) or str(bi_val).strip() == '') and (pd.notna(crm_val) and str(crm_val).strip() != ''):
                        bi_null_crm_value += 1
                    elif (pd.notna(crm_val) and str(crm_val).strip() != '') and (pd.notna(bi_val) and str(bi_val).strip() != ''):
                        different_values += 1
                    else:
                        different_values += 1
                
                debug_info['results'] = {
                    'crm_null_bi_value': crm_null_bi_value,
                    'bi_null_crm_value': bi_null_crm_value,
                    'different_values': different_values
                }
        
        field_debug_data.append(debug_info)
        
        match_rate = (match_count / total_rows * 100) if total_rows > 0 else 0
        display_name = get_field_display_name(col)
        
        field_stats.append({
            'field': display_name,
            'match': match_count,
            'no_match': no_match_count,
            'both_null': both_null_count,
            'match_rate': round(match_rate, 2)
        })
        
        detailed_stats.append({
            'field': display_name,
            'match': match_count,
            'both_null': both_null_count,
            'crm_null_bi_value': crm_null_bi_value,
            'bi_null_crm_value': bi_null_crm_value,
            'different_values': different_values
        })
    
    field_stats_df = pd.DataFrame(field_stats)
    detailed_stats_df = pd.DataFrame(detailed_stats)
    
    total_match = int(field_stats_df['match'].sum()) if not field_stats_df.empty else 0
    total_both_null = int(field_stats_df['both_null'].sum()) if not field_stats_df.empty else 0
    total_crm_null = int(detailed_stats_df['crm_null_bi_value'].sum()) if not detailed_stats_df.empty else 0
    total_bi_null = int(detailed_stats_df['bi_null_crm_value'].sum()) if not detailed_stats_df.empty else 0
    total_different = int(detailed_stats_df['different_values'].sum()) if not detailed_stats_df.empty else 0
    
    overall_stats = {
        'total_match': total_match,
        'total_both_null': total_both_null,
        'total_crm_null': total_crm_null,
        'total_bi_null': total_bi_null,
        'total_different': total_different,
    }
    
    row_stats = {
        'rows_with_nomatch': rows_with_nomatch,
        'rows_iso': rows_iso
    }
    
    return overall_stats, row_stats, field_stats_df, detailed_stats_df, field_debug_data

def create_quality_metrics_dashboard(field_stats_df, overall_stats):
    """Create quality metrics dashboard with detailed breakdown."""
    st.markdown("## ğŸ“Š MÃ©triques de qualitÃ© globales")
    
    total_match = overall_stats.get('total_match', 0)
    total_both_null = overall_stats.get('total_both_null', 0)
    total_crm_null = overall_stats.get('total_crm_null', 0)
    total_bi_null = overall_stats.get('total_bi_null', 0)
    total_different = overall_stats.get('total_different', 0)
    
    total_comparisons = total_match + total_both_null + total_crm_null + total_bi_null + total_different
    match_rate = (total_match / total_comparisons * 100) if total_comparisons > 0 else 0
    
    # PremiÃ¨re ligne de mÃ©triques
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ¯ Taux de correspondance global", f"{match_rate:.1f}%")
    with col2:
        st.metric("âœ… Total correspondances", f"{total_match:,}")
    with col3:
        st.metric("âšª Valeurs nulles (deux cÃ´tÃ©s)", f"{total_both_null:,}")
    with col4:
        st.metric("ğŸ”„ Valeurs diffÃ©rentes", f"{total_different:,}")
    
    # DeuxiÃ¨me ligne de mÃ©triques pour les cas null
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric("ğŸ“¤ CRM null / BI valeur", f"{total_crm_null:,}")
    with col6:
        st.metric("ğŸ“¥ BI null / CRM valeur", f"{total_bi_null:,}")
    with col7:
        total_no_match = total_crm_null + total_bi_null + total_different
        st.metric("âŒ Total Ã©carts", f"{total_no_match:,}")
    with col8:
        st.metric("ğŸ“Š Total comparaisons", f"{total_comparisons:,}")
    
    # Graphique dÃ©taillÃ©
    pie_data = pd.DataFrame([
        {'status': 'Correspondances', 'count': total_match},
        {'status': 'Valeurs nulles (deux cÃ´tÃ©s)', 'count': total_both_null},
        {'status': 'CRM null / BI valeur', 'count': total_crm_null},
        {'status': 'BI null / CRM valeur', 'count': total_bi_null},
        {'status': 'Valeurs diffÃ©rentes', 'count': total_different}
    ])
    
    colors = ["#7fbfdc", "#4cadb4", "#6ba6b6", "#78b495", "#82b86a"]
    
    fig_pie = px.pie(
        pie_data, 
        names='status', 
        values='count',
        title="ğŸ¥§ RÃ©partition dÃ©taillÃ©e de la qualitÃ© des donnÃ©es",
        color_discrete_sequence=colors
    )
    fig_pie.update_traces(hole=0.4)
    fig_pie.update_layout(showlegend=True, height=500)
    st.plotly_chart(fig_pie, use_container_width=True)

def create_field_analysis_charts(field_stats_df):
    """Create detailed field analysis charts - optimized."""
    st.markdown("## ğŸ“ˆ Analyse dÃ©taillÃ©e")
    
    if field_stats_df.empty:
        st.warning("Aucune donnÃ©e d'analyse de champ disponible")
        return
    
    # Graphique 1 : optimisÃ©
    df_sorted = field_stats_df.sort_values('match_rate')
    
    fig_match_rate = px.bar(
        df_sorted,
        x='match_rate',
        y='field',
        orientation='h',
        title="ğŸ“Š Taux de correspondance par champ (%)",
        color='match_rate',
        color_continuous_scale=[[0, "#6ba6b6"], [0.5, "#4cadb4"], [1, "#7fbfdc"]],
        text='match_rate'
    )
    fig_match_rate.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
    fig_match_rate.update_layout(height=max(400, len(field_stats_df) * 25), showlegend=False)
    st.plotly_chart(fig_match_rate, use_container_width=True)
    
    # Graphique 2 : optimisÃ© avec melt
    status_df = field_stats_df.melt(
        id_vars=['field'], 
        value_vars=['match', 'no_match', 'both_null'],
        var_name='status', 
        value_name='count'
    )
    
    # Mapper les noms
    status_mapping = {
        'match': 'Correspondances',
        'no_match': 'Ã‰carts', 
        'both_null': 'Valeurs nulles'
    }
    status_df['status'] = status_df['status'].map(status_mapping)
    
    color_map = {
        'Correspondances': '#7fbfdc',
        'Ã‰carts': '#6ba6b6',
        'Valeurs nulles': '#4cadb4'
    }
    
    fig_stacked = px.bar(
        status_df,
        x='field',
        y='count',
        color='status',
        title="ğŸ“š RÃ©partition dÃ©taillÃ©e par champ",
        color_discrete_map=color_map
    )
    fig_stacked.update_xaxes(tickangle=45)
    fig_stacked.update_layout(height=500)
    st.plotly_chart(fig_stacked, use_container_width=True)

def create_advanced_analytics(df, field_stats_df, detailed_stats_df):
    """Create advanced analytics with business rules."""
    st.markdown("## ğŸ”¬ Analyses avancÃ©es")
    
    if field_stats_df.empty or detailed_stats_df.empty:
        st.warning("Pas de donnÃ©es pour l'analyse avancÃ©e")
        return
    
    # Graphique de rÃ©partition dÃ©taillÃ©e par type
    st.markdown("### ğŸ“Š RÃ©partition dÃ©taillÃ©e par champ et type")
    
    try:
        detailed_data = []
        for _, row in detailed_stats_df.iterrows():
            detailed_data.extend([
                {'field': row['field'], 'type': 'Correspondances', 'count': row['match']},
                {'field': row['field'], 'type': 'Valeurs nulles (deux cÃ´tÃ©s)', 'count': row['both_null']},
                {'field': row['field'], 'type': 'CRM null / BI valeur', 'count': row['crm_null_bi_value']},
                {'field': row['field'], 'type': 'BI null / CRM valeur', 'count': row['bi_null_crm_value']},
                {'field': row['field'], 'type': 'Valeurs diffÃ©rentes', 'count': row['different_values']}
            ])
        
        detailed_df = pd.DataFrame(detailed_data)
        
        color_map = {
            'Correspondances': '#7fbfdc',
            'Valeurs nulles (deux cÃ´tÃ©s)': '#4cadb4',
            'CRM null / BI valeur': '#6ba6b6',
            'BI null / CRM valeur': '#78b495',
            'Valeurs diffÃ©rentes': '#82b86a'
        }
        
        fig_detailed = px.bar(
            detailed_df,
            x='field',
            y='count',
            color='type',
            title="ğŸ“š RÃ©partition dÃ©taillÃ©e par champ et type de situation",
            color_discrete_map=color_map
        )
        fig_detailed.update_xaxes(tickangle=45)
        fig_detailed.update_layout(height=600)
        st.plotly_chart(fig_detailed, use_container_width=True)
        
    except Exception as e:
        st.error(f"Erreur dans le graphique dÃ©taillÃ©: {str(e)}")
    
    # Matrice de priorisation 
    st.markdown("### ğŸ¯ Matrice de priorisation")
    
    try:
        df_priority = detailed_stats_df.copy()
        df_priority['total_records'] = (df_priority['match'] + df_priority['both_null'] + 
                                      df_priority['crm_null_bi_value'] + df_priority['bi_null_crm_value'] + 
                                      df_priority['different_values'])
        
        df_priority['total_records'] = df_priority['total_records'].replace(0, 1)
        
        # NOUVELLE LOGIQUE: Plus de different_values = Plus de complexitÃ©
        df_priority['different_values_rate'] = df_priority['different_values'] / df_priority['total_records']
        
        # NOUVELLE LOGIQUE: Plus de valeurs nulles (CRM ou BI) = Plus d'impact mÃ©tier  
        df_priority['null_values_rate'] = (df_priority['crm_null_bi_value'] + df_priority['bi_null_crm_value']) / df_priority['total_records']
        
        df_priority['fix_complexity'] = np.where(
            df_priority['different_values_rate'] == 0, 1,  # Pas de valeurs diffÃ©rentes = facile
            np.where(df_priority['different_values_rate'] <= 0.1, 2,  # Peu de valeurs diffÃ©rentes = assez facile
            np.where(df_priority['different_values_rate'] <= 0.3, 3,  # Moyen
            np.where(df_priority['different_values_rate'] <= 0.6, 4, 5)))  # Beaucoup = difficile
        )
        
        df_priority['business_impact'] = df_priority['null_values_rate'] * 5
        
        fig_priority = px.scatter(
            df_priority,
            x='fix_complexity',
            y='business_impact',
            hover_data=['field', 'different_values_rate', 'null_values_rate'],
            title="ğŸ¯ Matrice de priorisation (Impact mÃ©tier vs ComplexitÃ© de correction)",
            labels={
                'fix_complexity': 'ComplexitÃ© de correction (1=facile, 5=difficile)',
                'business_impact': 'Impact mÃ©tier (basÃ© sur valeurs nulles CRM/BI)'
            },
            color='business_impact',
            color_continuous_scale=[[0, "#7fbfdc"], [0.5, "#78b495"], [1, "#82b86a"]]
        )
        
        # Tous les points ont la mÃªme taille
        fig_priority.update_traces(
            marker=dict(
                size=12,  # Taille fixe pour tous les points
                line=dict(width=1, color='white')  # Bordure blanche pour mieux voir les points
            )
        )
        
        fig_priority.add_hline(y=2.5, line_dash="dash", line_color="gray", annotation_text="Impact moyen")
        fig_priority.add_vline(x=3, line_dash="dash", line_color="gray", annotation_text="ComplexitÃ© moyenne")
        
        fig_priority.add_annotation(x=1.5, y=4, text="ğŸš¨ PRIORITÃ‰ MAX<br>(Facile + Impact Ã©levÃ©)", 
                                   bgcolor="rgba(255,0,0,0.1)", bordercolor="red")
        fig_priority.add_annotation(x=4.5, y=4, text="ğŸ¯ PLANIFIER<br>(Difficile + Impact Ã©levÃ©)", 
                                   bgcolor="rgba(255,165,0,0.1)", bordercolor="orange")
        fig_priority.add_annotation(x=1.5, y=1, text="âœ… QUICK WINS<br>(Facile + Impact faible)", 
                                   bgcolor="rgba(0,255,0,0.1)", bordercolor="green")
        fig_priority.add_annotation(x=4.5, y=1, text="â³ REPORTER<br>(Difficile + Impact faible)", 
                                   bgcolor="rgba(128,128,128,0.1)", bordercolor="gray")
        
        fig_priority.update_layout(height=600)
        st.plotly_chart(fig_priority, use_container_width=True)
        
    except Exception as e:
        st.error(f"Erreur dans la matrice de priorisation: {str(e)}")

def create_field_by_field_analysis(field_debug_data, selected_fields):
    """Create field by field analysis for selected fields."""
    st.markdown("## ğŸ” Analyse champ par champ")
    
    if not selected_fields:
        st.info("SÃ©lectionnez des champs dans la barre latÃ©rale pour voir l'analyse dÃ©taillÃ©e.")
        return
    
    for debug_info in field_debug_data:
        if debug_info['col'] in selected_fields:
            st.write(f"### ğŸ” **Analyse de {debug_info['col']}:**")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"**Position:** colonne {debug_info['col_index']}")
            with col2:
                st.write(f"**Colonne CRM:** {debug_info['crm_col']}")
            with col3:
                st.write(f"**Colonne BI:** {debug_info['bi_col']}")
            
            st.write(f"**Lignes No Match:** {debug_info['no_match_count']}")
            
            if debug_info.get('sample_data') is not None and not debug_info['sample_data'].empty:
                st.write("**Ã‰chantillon des donnÃ©es No Match:**")
                st.dataframe(debug_info['sample_data'], use_container_width=True)
                
                if debug_info['results']:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("CRM null / BI valeur", debug_info['results']['crm_null_bi_value'])
                    with col2:
                        st.metric("BI null / CRM valeur", debug_info['results']['bi_null_crm_value'])
                    with col3:
                        st.metric("Valeurs diffÃ©rentes", debug_info['results']['different_values'])
            else:
                st.info("Aucune donnÃ©e No Match pour ce champ")
            
            st.write("---")


st.markdown("""
# Diagnostic CRM vs BI
### Diagnostic complet pour l'amÃ©lioration de la correspondance des donnÃ©es
""")

# Sidebar avec logique conditionnelle selon le mode
with st.sidebar:
    st.markdown("## ğŸ“ Upload de fichier(s)")
    
    if page == "ğŸ“„ Analyse Simple":
        # Mode Analyse Simple - 1 seul fichier
        uploaded_file = st.file_uploader(
            "Choisir un fichier de comparaison",
            type=["xlsx", "csv"],
            help="Fichier Excel ou CSV contenant les comparaisons CRM vs BI (max 200MB)"
        )
        uploaded_files = [uploaded_file] if uploaded_file else []
        
    else:  # Mode Analyse FragmentÃ©e
        # Mode Analyse FragmentÃ©e - plusieurs fichiers
        uploaded_files = st.file_uploader(
            "Choisir plusieurs fichiers Ã  combiner",
            type=["xlsx", "csv"],
            help="SÃ©lectionnez plusieurs fichiers Excel ou CSV Ã  analyser ensemble",
            accept_multiple_files=True
        )
        uploaded_file = None  # Pour la compatibilitÃ© avec le reste du code
    
    # Affichage des fichiers uploadÃ©s
    if uploaded_files and any(f is not None for f in uploaded_files):
        valid_files = [f for f in uploaded_files if f is not None]
        if len(valid_files) == 1:
            st.success(f"âœ… Fichier chargÃ©: {valid_files[0].name}")
        else:
            st.success(f"âœ… {len(valid_files)} fichiers chargÃ©s:")
            for i, file in enumerate(valid_files, 1):
                st.write(f"   {i}. {file.name}")
        
        st.markdown("## âš™ï¸ Options d'analyse")
        show_quality_metrics = st.checkbox("ğŸ“Š MÃ©triques de qualitÃ© globales", value=True)
        show_field_analysis = st.checkbox("ğŸ“ˆ Analyse dÃ©taillÃ©e", value=True)
        show_advanced = st.checkbox("ğŸ”¬ Analyses avancÃ©es", value=True)
        show_field_by_field = st.checkbox("ğŸ” Analyse champ par champ", value=False)
        
        # Selectbox pour les champs Ã  analyser (seulement si l'option est cochÃ©e)
        selected_fields = []
        if show_field_by_field:
            st.markdown("### ğŸ¯ SÃ©lection des champs")
            if 'df_combined' in st.session_state:
                df = st.session_state.df_combined
                eq_cols = [c for c in df.columns if "IsEquals" in c or "IsEqual" in c]
                selected_fields = st.multiselect(
                    "Choisir les champs Ã  analyser en dÃ©tail:",
                    options=eq_cols,
                    default=[],
                    help="SÃ©lectionnez les colonnes IsEquals que vous voulez analyser"
                )
            else:
                st.info("Veuillez d'abord charger un/des fichier(s) pour voir les champs disponibles")
        
        st.markdown("---")
        
        # Bouton 
        apply_analysis = st.button(
            "ğŸš€ Appliquer l'analyse", 
            type="primary",
            use_container_width=True,
            help="Lancer l'analyse avec les options sÃ©lectionnÃ©es"
        )
        
        if 'analysis_applied' not in st.session_state:
            st.session_state.analysis_applied = False
        
        if apply_analysis:
            st.session_state.analysis_applied = True
            st.session_state.show_quality_metrics = show_quality_metrics
            st.session_state.show_field_analysis = show_field_analysis
            st.session_state.show_advanced = show_advanced
            st.session_state.show_field_by_field = show_field_by_field
            st.session_state.selected_fields = selected_fields

# Logique de traitement des donnÃ©es
if uploaded_files and any(f is not None for f in uploaded_files) and st.session_state.get('analysis_applied', False):
    try:
        valid_files = [f for f in uploaded_files if f is not None]
        
        # VÃ©rifier si on doit recharger les donnÃ©es
        current_file_names = [f.name for f in valid_files]
        should_reload = (
            'df_combined' not in st.session_state or 
            st.session_state.get('last_file_names', []) != current_file_names
        )
        
        if should_reload:
            with st.spinner("ğŸ”„ Chargement et combinaison des fichiers..."):
                dataframes_list = []
                
                for file in valid_files:
                    file_bytes = file.read()
                    file.seek(0)  # Reset file pointer for potential reuse
                    df_temp = load_accounts_file(file_bytes, file.name)
                    dataframes_list.append(df_temp)
                    st.success(f"âœ… {file.name} chargÃ©: {len(df_temp)} lignes")
                
                # Combiner les DataFrames
                df_combined = combine_dataframes(dataframes_list)
                st.session_state.df_combined = df_combined
                st.session_state.last_file_names = current_file_names
        else:
            df_combined = st.session_state.df_combined
        
        # Analyse des donnÃ©es combinÃ©es
        with st.spinner("âš¡ Analyse en cours..."):
            overall_stats, row_stats, field_stats_df, detailed_stats_df, field_debug_data = compute_comprehensive_analysis(df_combined)
        
        # MÃ©triques de base
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š Total lignes", f"{len(df_combined):,}")
        with col2:
            eq_cols = [c for c in df_combined.columns if "IsEquals" in c]
            st.metric("ğŸ”— Champs comparÃ©s", len(eq_cols))
        with col3:
            st.metric("ğŸš¨ Lignes avec au moins 1 Ã©cart", f"{row_stats.get('rows_with_nomatch', 0):,}")
        with col4:
            st.metric("âœ… Lignes ISO", f"{row_stats.get('rows_iso', 0):,}")
        
        if page == "ğŸ§© Analyse FragmentÃ©e" and len(valid_files) > 1:
            with st.expander("ğŸ“‹ DÃ©tails des fichiers traitÃ©s"):
                files_info = []
                start_idx = 0
                for i, file in enumerate(valid_files):
                    file_bytes = file.read()
                    file.seek(0)
                    df_temp = load_accounts_file(file_bytes, file.name)
                    end_idx = start_idx + len(df_temp)
                    files_info.append({
                        'Fichier': file.name,
                        'Lignes': len(df_temp),
                        'Colonnes': len(df_temp.columns),
                        'Plage dans fichier combinÃ©': f"{start_idx + 1} - {end_idx}"
                    })
                    start_idx = end_idx
                
                st.dataframe(pd.DataFrame(files_info), use_container_width=True)
        

        if st.session_state.get('show_quality_metrics', True) and overall_stats:
            create_quality_metrics_dashboard(field_stats_df, overall_stats)
        
        if st.session_state.get('show_field_analysis', True) and not field_stats_df.empty:
            create_field_analysis_charts(field_stats_df)
        
        if st.session_state.get('show_advanced', True) and not field_stats_df.empty:
            create_advanced_analytics(df_combined, field_stats_df, detailed_stats_df)
        
        if st.session_state.get('show_field_by_field', False):
            selected_fields = st.session_state.get('selected_fields', [])
            create_field_by_field_analysis(field_debug_data, selected_fields)
        
        # AperÃ§u des donnÃ©es
        st.markdown("## ğŸ‘€ AperÃ§u des donnÃ©es")
        
        with st.expander("ğŸ“Š Statistiques rÃ©sumÃ©es"):
            st.dataframe(field_stats_df, use_container_width=True)
        
        with st.expander("ğŸ” Ã‰chantillon des donnÃ©es brutes"):
            st.dataframe(df_combined.head(20), use_container_width=True)
    
    except Exception as e:
        st.error(f"âŒ Erreur lors du traitement du/des fichier(s): {str(e)}")
        st.info("ğŸ’¡ VÃ©rifiez le format de vos fichiers et rÃ©essayez.")
        
        with st.expander("ğŸ” Informations de dÃ©bogage"):
            st.code(f"Type d'erreur: {type(e).__name__}")
            st.code(f"Message: {str(e)}")

elif uploaded_files and any(f is not None for f in uploaded_files) and not st.session_state.get('analysis_applied', False):
    st.info("ğŸ‘† Configurez vos options d'analyse dans la barre latÃ©rale et cliquez sur **'ğŸš€ Appliquer l'analyse'** pour commencer.")

else:
    # Welcome screen
    st.markdown(f"""
    ## ğŸ‘‹ Bienvenue dans l'outil d'analyse de qualitÃ© des donnÃ©es
    
    **Mode actuel: {page}**
    
    Cet outil vous permet d'analyser la qualitÃ© de correspondance entre vos donnÃ©es CRM et BI.
    
    ### ğŸ”„ Pour commencer :
    1. **ğŸ“ Uploadez votre/vos fichier(s)** dans la barre latÃ©rale (Excel ou CSV)
       - **Analyse Simple**: 1 seul fichier (max 200MB)
       - **Analyse FragmentÃ©e**: Plusieurs fichiers Ã  combiner automatiquement
    2. **âš™ï¸ Configurez les options** d'analyse selon vos besoins
    3. **ğŸš€ Cliquez sur "Appliquer l'analyse"** pour lancer le traitement
    4. **ğŸ“Š Explorez les rÃ©sultats** avec les graphiques interactifs
    
    ### ğŸ’¡ Avantages de l'analyse fragmentÃ©e :
    - **ğŸ”— Combinaison automatique** de plusieurs fichiers
    - **ğŸ“Š Analyse globale** sur l'ensemble des donnÃ©es
    - **ğŸ¯ Gestion intelligente** des structures diffÃ©rentes
    - **âš¡ Performance optimisÃ©e** pour de gros volumes
    
    ### âš ï¸ Optimisations de performance :
    - ğŸ”„ **La premiÃ¨re analyse peut prendre 1 minute** pour gÃ©nÃ©rer les diffÃ©rents graphiques
    - ğŸ’¾ Les donnÃ©es sont mises en cache pour accÃ©lÃ©rer les analyses suivantes
    """)